---
title: "Fully-Connected Spatial-Temporal Graph for Multivariate Time-Series Data"
Author: "Yucheng Wang, Yuecong Xu, Jianfei Yang, Min Wu, Xiaoli Li, Lihua Xie, Zhenghua Chen"
Published: "The Thirty-Eighth AAAI Conference on Artificial Intelligence"
Date: 2025-03-26
Category: time-series forecasting
---

# Introduction

Multivariate Time-Series (MTS) data는 다양한 곳에서 예측이나, 관리를 위해 사용됨. Spatial-Temporal (ST) dependecy를 잘 학습하는게 중요함. 전통적으로는 temporal 관계 학습하는 게 주 목적이었음. Spatial 관계는 약간 무시됨. 이를 해결하기 위해 Graph-NN (GNN)이 제안됨.

<br/>

기존 GNN은 크게 두 스텝으로 나뉨.

1. Each timestamp마다 개별 GNN 생성 (spatial 관계 학습)
2. 서로 다른 timestamp의 같은 feature에 대해 encoder를 통한 temporal 관계 학습

<br/>

이런 방식의 단점은 다른 timestamp에서의 다른 feature와의 관계를 학습하지 못함. (Different sEnsors at Different Timestamps; DEDT 문제라고 칭함)

이를 해결하기 위해서 Fully-Connected Spatial-Temporal Graph Neural Network (FC-STGNN)를 제안함. 크게 두 파트로 나뉨.

- `FC graph construction`: 모든 timestamp에서 모든 센서 연결이 목표. 시간적 관계를 고려해 Decay matrix 사용됨
- `FC graph convolution`: moving pooling GNN을 제안함. 각 timestamp 별로 특정 window 내 값이 average pooling되어 표현됨. 나중에는 concat해서 사용.

<figure style="margin: 1em 0">
  <img src="/articles/images/2025-03-26-01.png" alt="Overall structure" width="100%">
  <figcaption style="text-align:center">Figure 1. Overall structure</figcaption>
</figure>

# Related work

- Conventional methods for MTS data: CNNs, LSTMs, 1D-CNN, 2D-CNN, Transformer-based
  - Spatial dependency는 간과하고 있음
- GNN for MTS data: 1D-CNN+GNN, HierCorrPool, GraphSleepNet, HAGCN
  - DEDT 문제를 간과하고 있음

# Methodology

## FC graph construction

### Encoder for learned sensor features

1. MTS를 일정 크기$(f)$만큼 patch로 나눔.
2. Encoder를 통해 각 patch마다 각 sensor의 학습된 feature vector를 생성함.
3. 패치마다 생성된 sensor의 vector를 구분하며 temporal 관계를 강조하기 위해, positional encoding이 적용됨.

### FC graph construction

Node는 patch별 각 sensor임. Edge 정의가 필요. Edge에 대한 가정은 Correlated sensors는 similar한 특성을 가질 거임. 그래서 다음 similarity 식으로 edge를 정의함.

$$
e_{tr,ij} = g_s(z_{t,i}) ( g_s(z_{r,j}) )^T
$$

where $t,r \in [1, \hat{L}] $ and $i,j \in [1,N]$

<br/>

그래서 최종적으로 다음과 같음.

$$
G=(Z,E)
$$

$$
Z = [[z_{t,i}]^N_{i=1}]^{\hat{L}}_{t=1}
$$

$$
E = [[e_{tr,ij}]^N_{i,j=1}]^{\hat{L}}_{t,r=1}
$$

다른 timestamp에 대해서 similarity를 보고 있기 때문에, DEDT 문제를 해결할 수 있게 됨.

### Decay matrix

시간이 흐름에 따라 관계도 약해져야 하기 때문에, similarity에 $\delta$(=0.3,,,0.9)를 곱해줌.

<figure style="margin: 1em 0">
  <img src="/articles/images/2025-03-26-02.png" alt="Decay matrix" width="300px">
  <figcaption style="text-align:center">Figure 2. Decay matrix</figcaption>
</figure>

- 같은 시간에 대해서: $\times 1$
- 1 tick에 대해서: $\times \delta$
- 2 tick에 대해서: $\times \delta^2$
- n tick에 대해서: $\times \delta^n$

## FC graph convolution

Moving-pooling GNN을 정의함.

1. Patch 단위로 구성된 graph에 대해서 window를 설정함.
2. Window 단위로 Message Passing Neural Network (MPNN)를 수행함.
3. Window 단위로 sensor마다 average pooling을 수행함.
4. Pathc-Window 별로 압축된 고차원의 graph(혹은 그냥 vector로 사용)가 생성됨. Downstream task에 사용함.

Transformer 논문에서 제시한 바에 따라 parallel layers of graph construction and convolution 도입함. 각 layer에서의 output을 스택해서 MLP 같은 거로 task 수행함.

# Experimental Results

잔존 수명 예측 등 여러 데이터셋에서 SOTA 성능을 달성함.

<br/>

- Comparisons with SOTAs in C-MAPSS

| Models       | FD001 RMSE     | FD001 Score | FD002 RMSE     | FD002 Score | FD003 RMSE     | FD003 Score | FD004 RMSE     | FD004 Score |
| ------------ | -------------- | ----------- | -------------- | ----------- | -------------- | ----------- | -------------- | ----------- |
| AConvLSTM    | 13.10±0.37     | 286±45      | 13.11±0.21     | 737±65      | 12.13±0.53     | 276±75      | 14.64±0.31     | 1011±107    |
| DAGN         | 16.11±0.21     | 595±131     | 16.43±0.05     | 1242±116    | 18.05±0.25     | 1216±177    | 19.04±0.10     | 2321±105    |
| InFormer     | 13.13±0.22     | 263±19      | 13.20±0.15     | 715±71      | 12.58±0.24     | 228±15      | 14.16±0.49     | 1023±201    |
| AutoFormer   | 23.04±0.28     | 1063±73     | 16.51±0.47     | 1248±112    | 25.40±0.26     | 2034±163    | 20.31±0.14     | 2291±122    |
| GCN          | 12.58±0.22     | 237±24      | 13.78±0.22     | 849±62      | 11.92±0.15     | 218±33      | 14.44±0.32     | 967±66      |
| HAGCN        | 13.10±0.63     | 263±30      | 14.92±0.12     | 1086±87     | 13.46±0.30     | 327±52      | 14.66±0.25     | 880±150     |
| HierCorrPool | 12.64±0.23     | 227±21      | 13.23±0.31     | **709±61**  | 12.30±0.15     | 220±16      | 13.86±0.32     | 854±68      |
| MAGNN        | 12.63±0.32     | 246±25      | 13.09±0.13     | 714±57      | 12.15±0.16     | 253±32      | 14.30±0.26     | 978±137     |
| **Ours**     | **11.62±0.19** | **203±16**  | **13.04±0.13** | **738±49**  | **11.52±0.19** | **198±12**  | **13.62±0.25** | **816±63**  |

<br/>

- Comparison of model complexity

|            | FD001 of C-MAPSS |            |             |               | ISRUC-S3       |            |               |
| ---------- | ---------------- | ---------- | ----------- | ------------- | -------------- | ---------- | ------------- |
| Indicators | FLOPs            | # Weights  | Training /s | Inference /ms | FLOPs          | # Weights  | Inference /ms |
| GCN        | 1,793,288        | 38,625     | 73          | 2.34          | 17,194,912     | 111,662    | 2.78          |
| HAGCN      | 1,843,336        | 22,436     | 78          | 2.09          | 17,150,632     | 197,828    | 4.04          |
| HierCorr   | 2,717,034        | 1,071,906  | 89          | 2.34          | 24,998,334     | 7,929,590  | 2.65          |
| MAGNN      | 2,181,150        | 30,464     | 453         | 5.61          | 19,280,332     | 155,923    | 10.31         |
| **Ours**   | **856,072**      | **20,225** | **68**      | **2.03**      | **15,422,112** | **51,822** | **2.23**      |

# Comment

- 모든 timestamp에 대해 graph 생성하고 학습하는 게 생각보다 일반적인가 봄
- Novelty가 서로 다른 t에서 g를 이어준거 밖에 없음
- Task를 어떻게 수행하는지 모르곘는데, 이런 구조면 데이터셋에 따라 계산량이 엄청 많아질 수 있을 것으로 보임
